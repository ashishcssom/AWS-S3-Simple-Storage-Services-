{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<IMG align=\"center\" src=\"https://cdn.havecamerawilltravel.com/photographer/files/2013/03/Amazon-S3-1068x339.jpg\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> AWS S3(Simple Storage Services) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requirements\n",
    "-   boto3==1.16.52\n",
    "-   pandas==1.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Contents </center>\n",
    "\n",
    "[1. Clear the workspace](#1.-Clear-the-workspace)\n",
    "\n",
    "[2. Import dependencies](#2.-Import-dependencies)\n",
    "\n",
    "[3. Configure the boto3](#3.-Configure-the-boto3)\n",
    "\n",
    "[4. To add directory in S3](#4.-To-add-directory-in-S3)\n",
    "\n",
    "[5. To add file in S3](#5.-To-add-file-in-S3)\n",
    "\n",
    "[6. To load file from S3](#6.-To-load-file-from-S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clear the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure the boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`aws_access_key_id` and `aws_secret_access_key` are credentials required to do the mdification in S3 programatically. Don't forget to specify the `S3 region`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id=os.environ.get('aws_access_key_id'),\n",
    "    aws_secret_access_key=os.environ.get('aws_secret_access_key')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. To add directory in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bucket_name=\"xxxx\"\n",
    "Directory_name='xxxx:/xxxx/xxxx/xxxx/'\n",
    "Folder_in_S3='xxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_folder_to_s3(s3bucket, inputDir, s3Path):\n",
    "    \"\"\" To add the files with directory in S3 \"\"\"\n",
    "    print(\"Uploading results to s3 initiated...\")\n",
    "    print(\"Local Source:\",inputDir)\n",
    "    os.system(\"ls -ltR \" + inputDir)\n",
    "    print(\"Dest  S3path:\",s3Path)\n",
    "    try:\n",
    "        for path, subdirs, files in os.walk(inputDir):\n",
    "            for file in files:\n",
    "                dest_path = path.replace(inputDir,\"\")\n",
    "                __s3file = os.path.normpath('/' + dest_path + '/' + file).replace(\"\\\\\",\"/\")\n",
    "                __local_file = os.path.join(path, file)\n",
    "                print(\"upload : \", __local_file, \" to Target: \", __s3file, end=\"\")\n",
    "                s3bucket.upload_file(__local_file, s3Path +__s3file)\n",
    "                print(\" ...Success\")\n",
    "    except Exception as e:\n",
    "        print(\" ... Failed!! Quitting Upload!!\")\n",
    "        print(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3bucket = s3.Bucket(Bucket_name)\n",
    "upload_folder_to_s3(s3bucket, Directory_name, Folder_in_S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. To add file in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Make dataframes\n",
    "foo = pd.DataFrame({'x': [1, 2, 3], 'y': ['a', 'b', 'c']})\n",
    "# Save to csv\n",
    "foo.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(Bucket_name).upload_file('x:/xxxx/xxxx/xxxx/foo.csv',f'{Folder_in_S3}/f.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. To load file from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3.Bucket(Bucket_name).Object(f'{Folder_in_S3}/xxxx/xxxx.xlsx').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = obj['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(io.BytesIO(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
